import streamlit as st
import pandas as pd
import os
import base64
import matplotlib as plt
import seaborn as sns

from utils.cleaning import clean_data
from utils.dashboard import display_dashboard
from utils.scraping import scrap_data

# Configuration de l'application
st.set_page_config(page_title="My Scraping App", page_icon="üöÄ", layout="wide")

# Sidebar (Menu lat√©ral)
st.sidebar.title("Menu")

# D√©finition du chemin de l'image de fond
def get_base64_of_bin_file(bin_file):
    with open(bin_file, "rb") as file:
        return base64.b64encode(file.read()).decode()

def set_background(image_path):
    if os.path.exists(image_path):
        base64_img = get_base64_of_bin_file(image_path)
        st.markdown(
            f"""
            <style>
                .stApp {{
                    background: url(data:image/png;base64,{base64_img}) no-repeat center center fixed;
                    background-size: cover;
                }}
            </style>
            """,
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            f"""
            <style>
                .stApp {{
                    background-color: #f0f0f0;
                }}
            </style>
            """,
            unsafe_allow_html=True
        )

# Charger l'image de fond automatiquement depuis le projet
background_image_path = "assets/data.PNG"  # Changez le chemin selon votre projet
#set_background(background_image_path)

# Titre de l'application
st.title("üöÄ My Scraping App")

URLS = {
    "v√©hicules": "https://dakarvente.com/index.php?page=annonces_rubrique&url_categorie_2=vehicules&id=2&sort=&nb={}",
    "motos": "https://dakarvente.com/index.php?page=annonces_categorie&id=3&sort=&nb={}",
    "voitures en location": "https://dakarvente.com/index.php?page=annonces_categorie&id=8&sort=&nb={}",
    "t√©l√©phones": "https://dakarvente.com/index.php?page=annonces_categorie&id=32&sort=&nb={}"
}

option = st.sidebar.radio(
    "Choisir une option :",
    ("Scraping", "Dashboard", "WebScraper Data", "√âvaluer l'App")
)

# Option 1 : Scraping
if option == "Scraping":
    st.header("Scraping de donn√©es")
    st.write("Scrapez des donn√©es √† partir de plusieurs pages.")

    selected_category = st.selectbox("Choisir une cat√©gorie :", ["Toutes les cat√©gories"] + list(URLS.keys()))
    num_pages = st.number_input("Nombre de pages √† scraper :", min_value=1, max_value=50, value=2)
    clean_data_option = st.checkbox("Nettoyer les donn√©es avant affichage", value=True)

    def load_existing_data():
        if selected_category == "Toutes les cat√©gories":
            for category in URLS.keys():
                file_path = f"data/selenium_data/{category.lower().replace(' ', '_')}.csv"
                try:
                    df = pd.read_csv(file_path)
                    if clean_data_option:
                        df = clean_data(df)
                    st.markdown(f"### üìä Donn√©es existantes pour **{category}**")
                    st.dataframe(df)
                except FileNotFoundError:
                    st.warning(f"‚ö†Ô∏è Aucune donn√©e existante pour {category}.")
        else:
            file_path = f"data/{selected_category.lower().replace(' ', '_')}.csv"
            try:
                df = pd.read_csv(file_path)
                if clean_data_option:
                    df = clean_data(df)
                st.markdown(f"### üìä Donn√©es existantes pour **{selected_category}**")
                st.dataframe(df)
            except FileNotFoundError:
                st.warning(f"‚ö†Ô∏è Aucune donn√©e existante pour {selected_category}.")

    load_existing_data()

    if st.button("Lancer le scraping"):
        with st.spinner("Scraping en cours..."):
            if selected_category == "Toutes les cat√©gories":
                all_data = {}
                for category, url in URLS.items():
                    st.markdown(f"### üîÑ Scraping des **{category}**...")
                    data = scrap_data(url, max_pages=num_pages)
                    df = pd.DataFrame(data)
                    if clean_data_option:
                        df = clean_data(df)
                    all_data[category] = df
                    st.markdown(f"### üìä Donn√©es des {category}")
                    st.dataframe(df)
                    st.write("---")
                for category, df in all_data.items():
                    file_path = f"data/selenium_data/{category.lower().replace(' ', '_')}.csv"
                    df.to_csv(file_path, index=False)
                    st.success(f"Donn√©es sauvegard√©es pour {category} dans : `{file_path}`")
            else:
                data = scrap_data(URLS[selected_category], max_pages=num_pages)
                df = pd.DataFrame(data)
                if clean_data_option:
                    df = clean_data(df)
                st.markdown(f"### üìä Donn√©es des {selected_category}")
                st.dataframe(df)
                file_path = f"data/{selected_category.lower().replace(' ', '_')}.csv"
                df.to_csv(file_path, index=False)
                st.success(f"Donn√©es sauvegard√©es dans : `{file_path}`")
            st.rerun()

# Option 2 : Dashboard
elif option == "Dashboard":
    st.header("üìà Dashboard des donn√©es scrap√©es")

    # S√©lection de la cat√©gorie
    selected_dashboard_category = st.selectbox("Choisir une cat√©gorie √† analyser :", list(URLS.keys()))

    file_path = f"data/webscraper_data/{selected_dashboard_category.lower().replace(' ', '_')}.csv"
    try:
        df_dashboard = pd.read_csv(file_path)

        clean_data(df_dashboard)
        display_dashboard(df_dashboard, selected_dashboard_category)

    except FileNotFoundError:
        st.warning(f"‚ö†Ô∏è Aucune donn√©e trouv√©e pour {selected_dashboard_category}. Veuillez scraper d'abord.")

# Option 3 : WebScraper Data
elif option == "WebScraper Data":
    st.header("üåê Donn√©es WebScraper")
    st.write("T√©l√©chargez les fichiers de donn√©es scrap√©es disponibles dans `data/`.")

    # V√©rifier l'existence du dossier "data"
    data_folder = "data/webscraper_data"
    if not os.path.exists(data_folder):
        st.warning("‚ö†Ô∏è Le dossier 'data/' est introuvable. Veuillez d'abord scraper des donn√©es.")
    else:
        # Liste des fichiers disponibles dans le dossier 'data/'
        files = [f for f in os.listdir(data_folder) if f.endswith(".csv") or f.endswith(".json")]

        if files:
            for file in files:
                file_path = os.path.join(data_folder, file)

                # Lire le fichier pour le t√©l√©chargement
                with open(file_path, "rb") as f:
                    file_bytes = f.read()

                # Affichage avec ic√¥ne de t√©l√©chargement
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(f"üìÑ {file}")
                with col2:
                    st.download_button(
                        label="‚¨áÔ∏è",
                        data=file_bytes,
                        file_name=file,
                        mime="text/csv" if file.endswith(".csv") else "application/json"
                    )
        else:
            st.warning("‚ö†Ô∏è Aucun fichier disponible dans `data/`. Veuillez d'abord scraper des donn√©es.")

# Option 4 : √âvaluer l'App
elif option == "√âvaluer l'App":
    st.header("√âvaluer l'application")
    st.write("Merci de remplir ce formulaire pour nous aider √† am√©liorer l'application.")

    kobo_form_url = "https://ee.kobotoolbox.org/x/bCaC927U"  # Remplace par ton propre lien
    iframe_code = f'<iframe src="{kobo_form_url}" width="100%" height="600px"></iframe>'
    st.markdown(iframe_code, unsafe_allow_html=True)
